{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11372,"sourceType":"modelInstanceVersion","modelInstanceId":5388}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ankitaguha/showcasing-agile-safety-classifiers-with-gemma?scriptVersionId=175899614\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T20:25:37.448982Z","iopub.execute_input":"2024-05-05T20:25:37.44968Z","iopub.status.idle":"2024-05-05T20:25:38.31475Z","shell.execute_reply.started":"2024-05-05T20:25:37.449646Z","shell.execute_reply":"2024-05-05T20:25:38.313673Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/gemma/keras/gemma_instruct_2b_en/2/config.json\n/kaggle/input/gemma/keras/gemma_instruct_2b_en/2/tokenizer.json\n/kaggle/input/gemma/keras/gemma_instruct_2b_en/2/metadata.json\n/kaggle/input/gemma/keras/gemma_instruct_2b_en/2/model.weights.h5\n/kaggle/input/gemma/keras/gemma_instruct_2b_en/2/assets/tokenizer/vocabulary.spm\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Overview\nThis codelab illustrates how to create a customised text classifier using parameter efficient tuning (PET). Instead of fine-tuning the whole model, PET methods update only a small amount of parameters, which makes it relatively easy and fast to train. It also makes it easier for a model to learn new behaviors with relatively little training data. The methodology is described in detail in [Towards Agile Text Classifiers for Everyone](https://arxiv.org/abs/2302.06541) which shows how these techniques can be applied to a variety of safety tasks and achieve state of the art performance with only a few hundred training examples.\n\nThis codelab uses the [LoRA](https://arxiv.org/abs/2106.09685) PET method and the smaller Gemma model (gemma_instruct_2b_en) since that can be run faster and more efficiently. The colab covers the steps of ingesting data, formatting it for the LLM, training LoRA weights, and then evaluating the results. This codelab trains on the [ETHOS](https://arxiv.org/abs/2006.08328) dataset, a publicly available dataset for detecting hateful speech, built from YouTube and Reddit comments. When trained on only 200 examples (1/4 of the dataset) it achieves F1: 0.80 and ROC-AUC: 0.78, slightly above the SOTA currently reported on the [leaderboard](https://paperswithcode.com/sota/hate-speech-detection-on-ethos-binary) (at the time of writing, 15 Feb 2024). When trained on the full 800 examples, like it achieves an F1 score of 83.74 and a ROC-AUC score of 88.17. Larger models, like gemma_instruct_7b_en will generally perform better, but training and execution costs are also larger.\n\nTrigger Warning: because this codelab develops a safety classifier for detecting hateful speech, examples and evaluation of the results contains some horrible language.","metadata":{}},{"cell_type":"code","source":"#pip install upgrade pip\n!pip install wurlitzer\n!pip install -q -U keras-nlp\n!pip install -q -U keras\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T20:25:42.102344Z","iopub.execute_input":"2024-05-05T20:25:42.103006Z","iopub.status.idle":"2024-05-05T20:26:26.036726Z","shell.execute_reply.started":"2024-05-05T20:25:42.102976Z","shell.execute_reply":"2024-05-05T20:26:26.035722Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting wurlitzer\n  Downloading wurlitzer-3.1.0-py3-none-any.whl.metadata (2.5 kB)\nDownloading wurlitzer-3.1.0-py3-none-any.whl (8.4 kB)\nInstalling collected packages: wurlitzer\nSuccessfully installed wurlitzer-3.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1. Loading the Dataset\nIn this section you will load the dataset on which to train our classifier and preprocess it into a train and test set. You will use the popular research dataset ETHOS which was collected to detect hate speech in social media. You can find more information about how the dataset was collected in the paper [ETHOS: an Online Hate Speech Detection Dataset.](https://arxiv.org/abs/2006.08328)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ngh_root = 'https://raw.githubusercontent.com'\ngh_repo = 'intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset'\ngh_path = 'master/ethos/ethos_data/Ethos_Dataset_Binary.csv'\ndata_url = f'{gh_root}/{gh_repo}/{gh_path}'\n\ndf = pd.read_csv(data_url, delimiter=';')\ndf['hateful'] = (df['isHate'] >= df['isHate'].median()).astype(int)\n\n# Shuffle the dataset.\ndf = df.sample(frac=1, random_state=32)\n\n# Split into train and test.\ndf_train, df_test = df[:800],  df[800:]\n\n# Display a sample of the data.\ndf.head(5)[['hateful', 'comment']]","metadata":{"execution":{"iopub.status.busy":"2024-05-05T20:59:56.545199Z","iopub.execute_input":"2024-05-05T20:59:56.545571Z","iopub.status.idle":"2024-05-05T20:59:56.774264Z","shell.execute_reply.started":"2024-05-05T20:59:56.545534Z","shell.execute_reply":"2024-05-05T20:59:56.773394Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"     hateful                                            comment\n517        0  You said he but still not convinced this is a ...\n685        0    well, looks like its time to have another child\n706        0  to be honest I am part of the LGBT community a...\n182        1  What if we send every men to mars to start a n...\n829        0  It doesn't matter if you're black or white, ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hateful</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>517</th>\n      <td>0</td>\n      <td>You said he but still not convinced this is a ...</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>0</td>\n      <td>well, looks like its time to have another child</td>\n    </tr>\n    <tr>\n      <th>706</th>\n      <td>0</td>\n      <td>to be honest I am part of the LGBT community a...</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>1</td>\n      <td>What if we send every men to mars to start a n...</td>\n    </tr>\n    <tr>\n      <th>829</th>\n      <td>0</td>\n      <td>It doesn't matter if you're black or white, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Download and Instantiate the Model\nAs described in the documentation, you can easily use the Gemma model in many ways. With Keras, this is what you need to do:","metadata":{}},{"cell_type":"code","source":"import keras\nimport keras_nlp\n\n# For reproducibility purposes.\nkeras.utils.set_random_seed(1234)\n\n# Download the model from Kaggle using Keras.\nmodel = keras_nlp.models.GemmaCausalLM.from_preset('gemma_instruct_2b_en')\n\n# Set the sequence length to a small enough value to fit in memory in Colab.\nmodel.preprocessor.sequence_length = 128","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:00:07.066734Z","iopub.execute_input":"2024-05-05T21:00:07.06717Z","iopub.status.idle":"2024-05-05T21:01:22.028116Z","shell.execute_reply.started":"2024-05-05T21:00:07.067136Z","shell.execute_reply":"2024-05-05T21:01:22.027333Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-05 21:00:08.720803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-05 21:00:08.720900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-05 21:00:08.842066: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's test that the model is working by generating some text:","metadata":{}},{"cell_type":"code","source":"model.generate('Question: what is the capital of France? ', max_length=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:02:34.647512Z","iopub.execute_input":"2024-05-05T21:02:34.648781Z","iopub.status.idle":"2024-05-05T21:02:58.603177Z","shell.execute_reply.started":"2024-05-05T21:02:34.648729Z","shell.execute_reply":"2024-05-05T21:02:58.602143Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1714942977.502809      34 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1714942977.568780      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1714942977.637419      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'Question: what is the capital of France? \\n\\nAnswer: Paris. \\n\\nParis is the capital city of France and is known as the City of'"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3. Text Preprocessing and Separator Tokens\nTo help the model understand our intent better, you can preprocess the text and use separator tokens. This makes it less likely for the model to generate text that does not fit the expected format. For example, you might attempt to request a sentiment classification from the model by writing a prompt like this:\nClassify the following text into one of the following classes:[Positive,Negative]\n\nText: you look very nice today ImageClassification:\n\nIn this case, the model may or may not output what you are looking for. For example, if the text contains newline characters, it's likely to have a negative effect on the model performance. A more robust approach is to use separator tokens. The prompt then becomes:\n\nClassify the following text into one of the following classes:[Positive,Negative]\n<separator>\n\nText: you look very nice today\n<separator>\nPrediction:\n    \nThis can be abstracted using a function that preprocesses the text:","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def preprocess_text(\n    text: str,\n    labels: list[str],\n    instructions: str,\n    separator: str,\n) -> str:\n  prompt = f'{instructions}:[{\",\".join(labels)}]'\n  return separator.join([prompt, f'Text:{text}', 'Prediction:'])","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:04:41.649244Z","iopub.execute_input":"2024-05-05T21:04:41.649864Z","iopub.status.idle":"2024-05-05T21:04:41.654976Z","shell.execute_reply.started":"2024-05-05T21:04:41.649827Z","shell.execute_reply":"2024-05-05T21:04:41.653987Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Now, if you run the function using the same prompt and text as before, you should get the same output:","metadata":{}},{"cell_type":"code","source":"text = 'you look very nice today'\n\nprompt = preprocess_text(\n    text=text,\n    labels=['Positive', 'Negative'],\n    instructions='Classify the following text into one of the following classes',\n    separator='\\n<separator>\\n',\n)\n\nprint(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:05:06.990204Z","iopub.execute_input":"2024-05-05T21:05:06.991056Z","iopub.status.idle":"2024-05-05T21:05:06.996283Z","shell.execute_reply.started":"2024-05-05T21:05:06.991012Z","shell.execute_reply":"2024-05-05T21:05:06.995358Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Classify the following text into one of the following classes:[Positive,Negative]\n<separator>\nText:you look very nice today\n<separator>\nPrediction:\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Output Postprocessing\nThe outputs of the model are tokens with various probabilities. Normally, to generate text, you would select among the top few most probable tokens and construct sentences, paragraphs or even full documents. However, for the purpose of classification, what actually matters is whether the model believes that Positive is more probable than Negative or vice versa.\n\nGiven the model you instantiated earlier, this is how you can process its output into the independent probabilities of whether the next token is Positive or Negative:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n\ndef softmax_normalization(arr: np.ndarray) -> np.ndarray:\n  \"\"\"Normalizes logits values into probabilities summing to one.\"\"\"\n  arr_exp = np.exp(arr - np.max(arr))\n  return arr_exp / arr_exp.sum()\n\n\ndef compute_token_probability(\n    model: keras_nlp.models.GemmaCausalLM,\n    prompt: str,\n    target_tokens: list[str],\n) -> dict[str, float]:\n  # Shorthands.\n  preprocessor = model.preprocessor\n  tokenizer = preprocessor.tokenizer\n\n  # Identify output token offset.\n  (padding_mask,) = preprocessor.generate_preprocess([prompt])['padding_mask']\n  token_offset = sum(padding_mask.numpy()) - 1\n\n  # Compute prediction, extract only the next token's logits.\n  (logits,) = model.predict([prompt], verbose=0)\n  token_logits = logits[token_offset]\n\n  # Identify the token indices, which is the same as the ID for this tokenizer.\n  # NOTE: If a token is not found, it will be considered same as \"<unk>\".\n  token_ids = [tokenizer.token_to_id(token) for token in target_tokens]\n\n  # Compute the relative probability of each of the requested tokens.\n  probabilities = softmax_normalization([token_logits[ix] for ix in token_ids])\n\n  return dict(zip(target_tokens, probabilities))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:05:40.760099Z","iopub.execute_input":"2024-05-05T21:05:40.760831Z","iopub.status.idle":"2024-05-05T21:05:40.769495Z","shell.execute_reply.started":"2024-05-05T21:05:40.760797Z","shell.execute_reply":"2024-05-05T21:05:40.768279Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"You can test that function by running it with a the prompt you created earlier:","metadata":{}},{"cell_type":"code","source":"compute_token_probability(\n    model=model,\n    prompt=prompt,\n    target_tokens=['Positive', 'Negative'],\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:06:11.782979Z","iopub.execute_input":"2024-05-05T21:06:11.783835Z","iopub.status.idle":"2024-05-05T21:06:23.224452Z","shell.execute_reply.started":"2024-05-05T21:06:11.783796Z","shell.execute_reply":"2024-05-05T21:06:23.223504Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"W0000 00:00:1714943182.896105     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'Positive': 0.99994016, 'Negative': 5.9841288e-05}"},"metadata":{}}]},{"cell_type":"markdown","source":"# 5. Wrapping it all as a Classifier\nFor ease of use, you can wrap all of the functions you just created into a single sklearn-like classifier with easy to use and familiar functions like predict() and predict_score().","metadata":{}},{"cell_type":"code","source":"import dataclasses\n\n\n@dataclasses.dataclass(frozen=True)\nclass AgileClassifier:\n  \"\"\"Agile classifier to be wrapped around a LLM.\"\"\"\n\n  # The classes whose probability will be predicted.\n  labels: tuple\n\n  # Provide default instructions and control tokens, can be overridden by user.\n  instructions: str = 'Classify the following text into one of the following classes'\n  separator_token: str = '<separator>'\n  end_of_text_token: str = '<eos>'\n\n  def encode_for_prediction(self, x_text: str) -> str:\n    return preprocess_text(\n        text=x_text,\n        labels=self.labels,\n        instructions=self.instructions,\n        separator=self.separator_token,\n    )\n\n  def encode_for_training(self, x_text: str, y: int) -> str:\n    return ''.join([\n        self.encode_for_prediction(x_text),\n        self.labels[y],\n        self.end_of_text_token,\n    ])\n\n  def predict_score(\n      self,\n      model: keras_nlp.models.GemmaCausalLM,\n      x_text: str,\n  ) -> list[float]:\n    prompt = self.encode_for_prediction(x_text)\n    token_probabilities = compute_token_probability(\n        model=model,\n        prompt=prompt,\n        target_tokens=self.labels,\n    )\n    return [token_probabilities[token] for token in self.labels]\n\n  def predict(\n      self,\n      model: keras_nlp.models.GemmaCausalLM,\n      x_eval: str,\n  ) -> int:\n    return np.argmax(self.predict_score(model, x_eval))\n\n\nagile_classifier = AgileClassifier(labels=('Positive', 'Negative'))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:06:42.072093Z","iopub.execute_input":"2024-05-05T21:06:42.072428Z","iopub.status.idle":"2024-05-05T21:06:42.083471Z","shell.execute_reply.started":"2024-05-05T21:06:42.072402Z","shell.execute_reply":"2024-05-05T21:06:42.082414Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 6. Model Fine-Tuning\nLoRA stands for Low-Rank Adaptation. It's a fine-tuning technique that can be used to efficiently fine-tune large language models. You can read more about it in the [LoRA: Low-Rank Adaptation of Large Language Models paper](https://arxiv.org/abs/2106.09685).\n\nThe Keras implementation of Gemma provides a enable_lora() method that you can use for fine-tuning:","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4.\nmodel.backbone.enable_lora(rank=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:07:10.695274Z","iopub.execute_input":"2024-05-05T21:07:10.695965Z","iopub.status.idle":"2024-05-05T21:07:10.821629Z","shell.execute_reply.started":"2024-05-05T21:07:10.695933Z","shell.execute_reply":"2024-05-05T21:07:10.820892Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Training for more epochs will result in higher accuracy, until overfitting occurs.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Create dataset with preprocessed text + labels.\nmap_fn = lambda xy: agile_classifier.encode_for_training(*xy)\nx_train = list(map(map_fn, df_train[['comment', 'hateful']].values))\nds_train = tf.data.Dataset.from_tensor_slices(x_train).batch(2)\n\n# Compile the model using the Adam optimizer and appropriate loss function.\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Begin training.\nmodel.fit(ds_train, epochs=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:07:26.404786Z","iopub.execute_input":"2024-05-05T21:07:26.405627Z","iopub.status.idle":"2024-05-05T21:28:03.202056Z","shell.execute_reply.started":"2024-05-05T21:07:26.405595Z","shell.execute_reply":"2024-05-05T21:28:03.20108Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1714943307.579431     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 736ms/step - loss: 1.1365 - sparse_categorical_accuracy: 0.5874\nEpoch 2/4\n\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 734ms/step - loss: 0.7579 - sparse_categorical_accuracy: 0.6662\nEpoch 3/4\n\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 735ms/step - loss: 0.6818 - sparse_categorical_accuracy: 0.6894\nEpoch 4/4\n\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 734ms/step - loss: 0.5922 - sparse_categorical_accuracy: 0.7219\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7e778040a800>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 7. Inspect the Results\nYou can now inspect the output of the agile classifier you just trained. This code will output the predicted class score given a piece of text:","metadata":{}},{"cell_type":"code","source":"text = 'you look really nice today'\nscores = agile_classifier.predict_score(model, text)\ndict(zip(agile_classifier.labels, scores))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:28:34.276142Z","iopub.execute_input":"2024-05-05T21:28:34.276514Z","iopub.status.idle":"2024-05-05T21:28:42.744098Z","shell.execute_reply.started":"2024-05-05T21:28:34.276483Z","shell.execute_reply":"2024-05-05T21:28:42.743092Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"W0000 00:00:1714944522.344539     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'Positive': 0.99900454, 'Negative': 0.0009954689}"},"metadata":{}}]},{"cell_type":"markdown","source":"# 8. Model Evaluation\nFinally, you'll evaluate the performance of our model using two common metrics, the F1 score and the AUC-ROC. The F1 score captures false negative and false positive errors by evaluating the harmonic mean of the precision and recall at a certain classification threshold. The AUC-ROC on the other hand captures the tradeoff between the true positive rate and the false positive rate across a variety of thresholds and computes the area under this curve.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score\n\ny_true = df_test['hateful'].values\n# Compute the scores (aka probabilities) for each of the labels.\ny_score = [agile_classifier.predict_score(model, x) for x in df_test['comment']]\n# The label with highest score is considered the predicted class.\ny_pred = np.argmax(y_score, axis=1)\n# Extract the probability of a comment being considered hateful.\ny_prob = [x[agile_classifier.labels.index('Negative')] for x in y_score]\n\n# Compute F1 and AUC-ROC scores.\nprint(f'F1: {f1_score(y_true, y_pred):.2f}')\nprint(f'AUC-ROC: {roc_auc_score(y_true, y_prob):.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:29:06.030496Z","iopub.execute_input":"2024-05-05T21:29:06.030863Z","iopub.status.idle":"2024-05-05T21:31:27.194607Z","shell.execute_reply.started":"2024-05-05T21:29:06.030833Z","shell.execute_reply":"2024-05-05T21:31:27.192909Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"F1: 0.84\nAUC-ROC: 0.88\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Another interesting way to evaluate model predictions are confusion matrices. A confusion matrix will visually depict the different kinds of prediction errors.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_true, y_pred)\nConfusionMatrixDisplay(\n  confusion_matrix=cm,\n  display_labels=agile_classifier.labels,\n).plot()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:31:32.611471Z","iopub.execute_input":"2024-05-05T21:31:32.612137Z","iopub.status.idle":"2024-05-05T21:31:32.934743Z","shell.execute_reply.started":"2024-05-05T21:31:32.612107Z","shell.execute_reply":"2024-05-05T21:31:32.933839Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7e7790246170>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, you can also look at the ROC curve to get a sense of potential prediction errors when using different scoring thresholds.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import RocCurveDisplay, roc_curve\n\n\nfpr, tpr, _ = roc_curve(y_true, y_score, pos_label=1)\nRocCurveDisplay(fpr=fpr, tpr=tpr).plot()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T21:31:55.822774Z","iopub.execute_input":"2024-05-05T21:31:55.823132Z","iopub.status.idle":"2024-05-05T21:31:56.817838Z","shell.execute_reply.started":"2024-05-05T21:31:55.823106Z","shell.execute_reply":"2024-05-05T21:31:56.816601Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RocCurveDisplay, roc_curve\n\u001b[0;32m----> 3\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m RocCurveDisplay(fpr\u001b[38;5;241m=\u001b[39mfpr, tpr\u001b[38;5;241m=\u001b[39mtpr)\u001b[38;5;241m.\u001b[39mplot()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:753\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m--> 753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m    755\u001b[0m assert_all_finite(y_score)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1194\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1204\u001b[0m )\n","\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (198, 2) instead."],"ename":"ValueError","evalue":"y should be a 1d array, got an array of shape (198, 2) instead.","output_type":"error"}]}]}